# ğŸï¸ VFIDiff â€” Motion-Aware Generative Multi-frame Interpolation

Diffusion-based **Video Frame Interpolation (VFI)** built upon **ResShift**, with **optical-flowâ€“guided** modifications to the diffusion process.

> âœ… **Hack diffusion here:** `models/script_util.py` â†’ `create_gaussian_diffusion()` â†’ **`GaussianDiffusion`**

---

## ğŸ§­ Overview

Pipeline:

**Inference / Training Script** â†’ **ResShift Sampler** â†’ **Gaussian Diffusion Model** â†’ **Forward & Reverse Diffusion**

---

## ğŸ—ºï¸ Project Map

```text
inference / training entry
        â†“
 ResShiftSampler (sampler.py)
        â†“
 GaussianDiffusion (models/script_util.py)
        â†“
 forward: q_sample   +   reverse: p_sample*
```

---

## ğŸ§© Code Structure

### ğŸš€ Inference
- **Entry:** `inference_resshift.py`
- Creates a `ResShiftSampler`
- Calls `sampler.inference(...)`
- Sampler internally relies on a Gaussian diffusion model

### ğŸ§  Diffusion Model
- Built in: `sampler.py` â†’ `build_model(...)`
- Config: `configs/realsr_swinunet_realesrgan256.yaml`
  - `target: models.script_util.create_gaussian_diffusion`
- Therefore, diffusion modifications should be made in:
  - `models/script_util.py`
    - `create_gaussian_diffusion()`
    - `GaussianDiffusion`

---

## ğŸ” Diffusion Process

### â• Forward Diffusion (Noising)
- `GaussianDiffusion.q_sample`

### â– Reverse Diffusion (Sampling)
- `GaussianDiffusion.p_sample`
- `GaussianDiffusion.p_sample_loop`
- `GaussianDiffusion.p_sample_loop_progressive`

These functions define how samples are generated across diffusion timesteps.

---

## ğŸ‹ï¸ Training

```bash
CUDA_VISIBLE_DEVICES=0 torchrun \
  --standalone --nproc_per_node=1 --nnodes=1 \
  main.py \
  --cfg_path configs/realsr_swinunet_realesrgan256.yaml \
  --save_dir ./logs
```

---

## ğŸ§ª Inference

```bash
python inference_resshift.py \
  -i /root/autodl-tmp/testdata/Val_SR/lq \
  -o /root/autodl-tmp/fasttest \
  --task realsr \
  --scale 4 \
  --version v3
```

---
